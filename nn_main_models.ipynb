{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_main_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FKqPQui5rjJR",
        "65_2RGHPq_Nj"
      ],
      "authorship_tag": "ABX9TyMy3KHhVMlHWOHBwzeaI01C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romanAVJ/Ido_proyectos/blob/master/nn_main_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbJvQeQamL4M"
      },
      "source": [
        "# Get .py files and data from GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSgMAWnFokf-"
      },
      "source": [
        "First clone the entire repository to local file and then start "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMk-JY9qnzb7",
        "outputId": "b871d4cf-1934-4310-d583-2dbefede82ed"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/romanAVJ/Optimal_Bets_PremierLeague.git cloned-repo\n",
        "\n",
        "# move to folder \"cloned repo\"\n",
        "%cd cloned-repo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 98 (delta 19), reused 94 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (98/98), done.\n",
            "/content/cloned-repo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5qIdE0_o9Ui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a3587d-0c90-43fb-dd2d-f5ccb62e69d0"
      },
      "source": [
        "# look that we are in the right place\n",
        "! ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data  nn_models.ipynb  README.md  Results  Source\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFhBn3z9p2dE"
      },
      "source": [
        "## Import libraries and .py files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsjAqxfho-o1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec2512fc-9e3d-476f-ff45-b9899b349947"
      },
      "source": [
        "# manually install dependencies of files\n",
        "# adjustText\n",
        "!pip install adjustText \n",
        "!pip install keras-tuner --upgrade\n",
        "\n",
        "# uninstall scikit-learn (old verison) and install new version (>= 0.24)\n",
        "!pip uninstall scikit-learn -y\n",
        "!pip install -U scikit-learn\n",
        "!pip uninstall sklearn -y\n",
        "!pip install -U sklearn\n",
        "\n",
        "# get libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "\n",
        "from tensorflow import keras\n",
        "import os \n",
        "import random\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from adjustText import adjust_text\n",
        "\n",
        "import Source.statistical_learning_model.nn_utils as nn_utils_ravj\n",
        "from sklearn.model_selection import TimeSeriesSplit\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adjustText\n",
            "  Downloading adjustText-0.7.3.tar.gz (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from adjustText) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from adjustText) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->adjustText) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->adjustText) (1.15.0)\n",
            "Building wheels for collected packages: adjustText\n",
            "  Building wheel for adjustText (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adjustText: filename=adjustText-0.7.3-py3-none-any.whl size=7094 sha256=623b2a77299c242646ddfbcda66da80c06bcb594480396155aaeddceae5aa76c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/98/32/afbf902d8f040fadfdf0a44357e4ab750afe165d873bf5893d\n",
            "Successfully built adjustText\n",
            "Installing collected packages: adjustText\n",
            "Successfully installed adjustText-0.7.3\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.5.30)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.40.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.5.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.0.4 kt-legacy-1.0.4\n",
            "Found existing installation: scikit-learn 0.22.2.post1\n",
            "Uninstalling scikit-learn-0.22.2.post1:\n",
            "  Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "Successfully installed scikit-learn-1.0 threadpoolctl-2.2.0\n",
            "Found existing installation: sklearn 0.0\n",
            "Uninstalling sklearn-0.0:\n",
            "  Successfully uninstalled sklearn-0.0\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=eea43463dbd75a34befcd1bd673c2bd2278f4f1614916a91329681220af65c7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1_mWG1zq-wY"
      },
      "source": [
        "# Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKqPQui5rjJR"
      },
      "source": [
        "## Tidy dataframes and get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqkp6c0krED8"
      },
      "source": [
        "## data functions\n",
        "def get_dummies_results(df, var='y', prefix='y'):\n",
        "    # working data frame\n",
        "    df_work = df.copy()\n",
        "    \n",
        "    # one hot encode results\n",
        "    y = pd.get_dummies(df_work[var], prefix=prefix, drop_first=False, dtype=int)\n",
        "    names_y = y.columns.values\n",
        "    \n",
        "    # append to dataframe\n",
        "    df_work[names_y] = y\n",
        "    \n",
        "    # reorder columns\n",
        "    columns_names = df_work.columns.values\n",
        "    columns_names = np.concatenate([names_y, columns_names[:-3]]) # number of y dummies'\n",
        "    df_work = df_work[columns_names]\n",
        "    \n",
        "    # drop result\n",
        "    df_work.drop(columns=var, inplace=True)\n",
        "    \n",
        "    return(df_work, list(names_y))\n",
        "\n",
        "def split_trainvaltest(df, queries, objective_var='y', var='x'):    \n",
        "    # working dataframe\n",
        "    df_work = df.copy()    \n",
        "    \n",
        "    # get train, validation and test\n",
        "    dbb = {}    \n",
        "    for k,v in queries.items():\n",
        "        df_subset = df_work.query(v)\n",
        "        \n",
        "        # save objective and covariables in dataframe\n",
        "        dbb[k] = {'y': df_subset[objective_var], 'X': df_subset[var]}\n",
        "        \n",
        "    return(dbb)\n",
        "\n",
        "def tidy_bdd(df, queries, objective_var='y', var='x'): \n",
        "    # working data frame\n",
        "    df_work = df.copy()\n",
        "    \n",
        "    # get dummies\n",
        "    df_work, names_y = get_dummies_results(df_work, var=objective_var, prefix=objective_var)\n",
        "    \n",
        "    # mutate matchweek to normalize it (lost generalization in functions)\n",
        "    df_work['matchweek'] = df_work.groupby('season')['matchweek'].\\\n",
        "        transform(lambda x: (x - min(x))/(max(x) - min(x)))   \n",
        "    \n",
        "    # get train, validation and test\n",
        "    dbb = split_trainvaltest(df_work, queries, objective_var=names_y, var=var)  \n",
        "    \n",
        "    return(dbb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65_2RGHPq_Nj"
      },
      "source": [
        "## Generate models for hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4LIexhMq_UJ"
      },
      "source": [
        "# model 1:  Elastic Net\n",
        "def build_model_elastic(hp):\n",
        "  # init randomness\n",
        "  nn_utils_ravj._reset_random_seeds(8)\n",
        "  n_covars = 21\n",
        "  n_l = 4\n",
        "\n",
        "  #### hyper params ####\n",
        "  # lambda penalization\n",
        "  dic_lambdas = {\n",
        "      'layer' + str(i+1): hp.Float(\n",
        "        name='elastic_lambda_l' + str(i+1),\n",
        "        min_value=1e-4,\n",
        "        max_value=1e-2\n",
        "      ) \n",
        "      for i in range(n_l)\n",
        "  }\n",
        "\n",
        "  # alpha (convex combination between lasso & ridge)\n",
        "  dic_alphas = {\n",
        "      'layer' + str(i+1): hp.Float(\n",
        "        name='elastic_alpha_l' + str(i+1),\n",
        "        min_value=0,\n",
        "        max_value=1,\n",
        "        default=0.5\n",
        "      ) for i in range(n_l)\n",
        "  }\n",
        "\n",
        "  # number of neurons\n",
        "  # create a funnel architecture\n",
        "  dic_units = dict()\n",
        "  for i in range(n_l - 1):\n",
        "    if i == 0:\n",
        "      dic_units['layer1'] = hp.Int(\n",
        "        name='units_l1',\n",
        "        min_value=n_covars,\n",
        "        max_value=n_covars*2,\n",
        "        step=4,\n",
        "        default=n_covars # initial value\n",
        "      )\n",
        "    else:\n",
        "      dic_units['layer' + str(i+1)] = hp.Int(\n",
        "        name='units_l' + str(i+1),\n",
        "        min_value=dic_units['layer' + str(i)],\n",
        "        max_value=dic_units['layer' + str(i)]*2,\n",
        "        step=4,\n",
        "        default=dic_units['layer' + str(i)] # initial value\n",
        "      )\n",
        "\n",
        "  # learning rate\n",
        "  lr_r = hp.Choice(\n",
        "      name = \"lr\", \n",
        "      values = [1e-2, 1e-3, 1e-4]\n",
        "    )\n",
        "\n",
        "  #### create model ####\n",
        "  model = keras.Sequential()\n",
        "  # layers\n",
        "  for i in range(n_l - 1):\n",
        "    ikey = str(i+1)\n",
        "    model.add(\n",
        "        keras.layers.Dense(\n",
        "            units=dic_units['layer' + ikey],\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal',\n",
        "            kernel_regularizer=keras.regularizers.l1_l2(\n",
        "                l1=dic_lambdas['layer' + ikey] * dic_alphas['layer' + ikey],     # Hastie & Tibshiranie formulation of elastic net \n",
        "                l2=dic_lambdas['layer' + ikey] * (1 - dic_alphas['layer' + ikey]) / 2  # Hastie & Tibshiranie formulation of elastic net \n",
        "              ),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "    )\n",
        "\n",
        "  # final layer\n",
        "  model.add(\n",
        "      keras.layers.Dense(\n",
        "        units=3, # three final classes\n",
        "        activation='softmax',\n",
        "        kernel_initializer=keras.initializers.GlorotNormal(),\n",
        "        kernel_regularizer=keras.regularizers.l1_l2(\n",
        "            l1=dic_lambdas['layer' + str(n_l)] * dic_alphas['layer' + str(n_l)],\n",
        "            l2=dic_lambdas['layer' + str(n_l)] * (1 - dic_alphas['layer' + str(n_l)]) / 2  \n",
        "          ),\n",
        "        dtype=np.float64          \n",
        "      )\n",
        "  )\n",
        "\n",
        "  # compile model\n",
        "  model.compile(\n",
        "        optimizer=keras.optimizers.Nadam(learning_rate=lr_r),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return(model)\n",
        "\n",
        "\n",
        "# model 2:  Lasso\n",
        "def build_model_lasso(hp):\n",
        "  # init randomness\n",
        "  nn_utils_ravj._reset_random_seeds(8)\n",
        "  n_covars = 21\n",
        "  n_l = 4\n",
        "\n",
        "  #### hyper params ####\n",
        "  # lambda penalization\n",
        "  dic_lambdas = {\n",
        "      'layer' + str(i+1): hp.Float(\n",
        "        name='elastic_lambda_l' + str(i+1),\n",
        "        min_value=1e-4,\n",
        "        max_value=1e-2\n",
        "      ) \n",
        "      for i in range(n_l)\n",
        "  }\n",
        "\n",
        "  # number of layers\n",
        "  # create a funnel architecture\n",
        "  dic_units = dict()\n",
        "  for i in range(n_l - 1):\n",
        "    if i == 0:\n",
        "      dic_units['layer1'] = hp.Int(\n",
        "        name='units_l1',\n",
        "        min_value=n_covars,\n",
        "        max_value=n_covars*2,\n",
        "        step=4,\n",
        "        default=n_covars # initial value\n",
        "      )\n",
        "    else:\n",
        "      dic_units['layer' + str(i+1)] = hp.Int(\n",
        "        name='units_l' + str(i+1),\n",
        "        min_value=dic_units['layer' + str(i)],\n",
        "        max_value=dic_units['layer' + str(i)]*2,\n",
        "        step=4,\n",
        "        default=dic_units['layer' + str(i)] # initial value\n",
        "      )\n",
        "\n",
        "  # learning rate\n",
        "  lr_r = hp.Choice(\n",
        "      name = \"lr\", \n",
        "      values = [1e-2, 1e-3, 1e-4]\n",
        "    )\n",
        "\n",
        "  #### create model ####\n",
        "  model = keras.Sequential()\n",
        "  # layers\n",
        "  for i in range(n_l - 1):\n",
        "    ikey = str(i+1)\n",
        "    model.add(\n",
        "        keras.layers.Dense(\n",
        "            units=dic_units['layer' + ikey],\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal',\n",
        "            kernel_regularizer=keras.regularizers.l1(dic_lambdas['layer' + ikey]),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "    )\n",
        "\n",
        "  # final layer\n",
        "  model.add(\n",
        "      keras.layers.Dense(\n",
        "        units=3, # three final classes\n",
        "        activation='softmax',\n",
        "        kernel_initializer=keras.initializers.GlorotNormal(),\n",
        "        kernel_regularizer=keras.regularizers.l1(dic_lambdas['layer' + ikey]),\n",
        "        dtype=np.float64          \n",
        "      )\n",
        "  )\n",
        "\n",
        "  # compile model\n",
        "  model.compile(\n",
        "        optimizer=keras.optimizers.Nadam(learning_rate=lr_r),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return(model)\n",
        "\n",
        "\n",
        "# model 3:  Ridge\n",
        "def build_model_ridge(hp):\n",
        "  # init randomness\n",
        "  nn_utils_ravj._reset_random_seeds(8)\n",
        "  n_covars = 21\n",
        "  n_l = 4\n",
        "\n",
        "\n",
        "  #### hyper params ####\n",
        "  # lambda penalization\n",
        "  dic_lambdas = {\n",
        "      'layer' + str(i+1): hp.Float(\n",
        "        name='elastic_lambda_l' + str(i+1),\n",
        "        min_value=1e-4,\n",
        "        max_value=1e-2\n",
        "      ) \n",
        "      for i in range(n_l)\n",
        "  }\n",
        "\n",
        "  # number of neurons\n",
        "  # create a funnel architecture\n",
        "  dic_units = dict()\n",
        "  for i in range(n_l - 1):\n",
        "    if i == 0:\n",
        "      dic_units['layer1'] = hp.Int(\n",
        "        name='units_l1',\n",
        "        min_value=n_covars,\n",
        "        max_value=n_covars*2,\n",
        "        step=4,\n",
        "        default=n_covars # initial value\n",
        "      )\n",
        "    else:\n",
        "      dic_units['layer' + str(i+1)] = hp.Int(\n",
        "        name='units_l' + str(i+1),\n",
        "        min_value=dic_units['layer' + str(i)],\n",
        "        max_value=dic_units['layer' + str(i)]*2,\n",
        "        step=4,\n",
        "        default=dic_units['layer' + str(i)] # initial value\n",
        "      )\n",
        "\n",
        "  # learning rate\n",
        "  lr_r = hp.Choice(\n",
        "      name = \"lr\", \n",
        "      values = [1e-2, 1e-3, 1e-4]\n",
        "    )\n",
        "\n",
        "  #### create model ####\n",
        "  model = keras.Sequential()\n",
        "  # layers\n",
        "  for i in range(n_l - 1):\n",
        "    ikey = str(i+1)\n",
        "    model.add(\n",
        "        keras.layers.Dense(\n",
        "            units=dic_units['layer' + ikey],\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal',\n",
        "            kernel_regularizer=keras.regularizers.l2(dic_lambdas['layer' + ikey]),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "    )\n",
        "\n",
        "  # final layer\n",
        "  model.add(\n",
        "      keras.layers.Dense(\n",
        "        units=3, # three final classes\n",
        "        activation='softmax',\n",
        "        kernel_initializer=keras.initializers.GlorotNormal(),\n",
        "        kernel_regularizer=keras.regularizers.l2(dic_lambdas['layer' + ikey]),\n",
        "        dtype=np.float64          \n",
        "      )\n",
        "  )\n",
        "\n",
        "  # compile model\n",
        "  model.compile(\n",
        "        optimizer=keras.optimizers.Nadam(learning_rate=lr_r),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return(model)\n",
        "\n",
        "\n",
        "# model 4:  DropOut\n",
        "def build_model_dropout(hp):\n",
        "  # init randomness\n",
        "  nn_utils_ravj._reset_random_seeds(8)\n",
        "  n_covars = 21\n",
        "  n_l = 4\n",
        "\n",
        "  #### hyper params ####\n",
        "  # dropout\n",
        "  dic_dropout_rate = {\n",
        "      'layer' + str(i+1): hp.Float(\n",
        "        name='rate_l' + str(i+1),\n",
        "        min_value=1e-6,\n",
        "        max_value=0.5,\n",
        "        sampling='log'\n",
        "        ) \n",
        "      for i in range(n_l - 1)\n",
        "  }\n",
        "\n",
        "  # number of layers\n",
        "  # create a funnel architecture\n",
        "  dic_units = dict()\n",
        "  for i in range(n_l - 1):\n",
        "    if i == 0:\n",
        "      dic_units['layer1'] = hp.Int(\n",
        "        name='units_l1',\n",
        "        min_value=n_covars,\n",
        "        max_value=n_covars*2,\n",
        "        step=4,\n",
        "        default=n_covars # initial value\n",
        "      )\n",
        "    else:\n",
        "      dic_units['layer' + str(i+1)] = hp.Int(\n",
        "        name='units_l' + str(i+1),\n",
        "        min_value=dic_units['layer' + str(i)],\n",
        "        max_value=dic_units['layer' + str(i)]*2,\n",
        "        step=4,\n",
        "        default=dic_units['layer' + str(i)] # initial value\n",
        "      )\n",
        "\n",
        "  # learning rate\n",
        "  lr_r = hp.Choice(\n",
        "      name = \"lr\", \n",
        "      values = [1e-2, 1e-3, 1e-4]\n",
        "    )\n",
        "\n",
        "  #### create model ####\n",
        "  model = keras.Sequential()\n",
        "  \n",
        "  # layers\n",
        "  for i in range(n_l - 1):\n",
        "    ikey = str(i+1)\n",
        "    # model layer\n",
        "    model.add(\n",
        "        keras.layers.Dense(\n",
        "            units=dic_units['layer' + ikey],\n",
        "            activation='relu',\n",
        "            kernel_initializer='he_normal',\n",
        "            dtype=np.float64\n",
        "        )    \n",
        "    )\n",
        "    # model dropout\n",
        "    model.add(\n",
        "        keras.layers.Dropout(rate=dic_dropout_rate['layer' + ikey])        \n",
        "    )\n",
        "\n",
        "\n",
        "  # final layer\n",
        "  model.add(\n",
        "      keras.layers.Dense(\n",
        "        units=3, # three final classes\n",
        "        activation='softmax',\n",
        "        kernel_initializer=keras.initializers.GlorotNormal(),\n",
        "        dtype=np.float64          \n",
        "      )\n",
        "  )\n",
        "\n",
        "  # compile model\n",
        "  model.compile(\n",
        "        optimizer=keras.optimizers.Nadam(learning_rate=lr_r),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "  return(model)\n",
        "\n",
        "# model 5:  Batch Normalization\n",
        "def build_model_bn(hp):\n",
        "    \"\"\"\n",
        "    Batch Normalization _before_ the activation function, as argued by\n",
        "    F. Chollet and paper authors: S. Ioffe & C. Szegedy\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    hp : TYPE\n",
        "        DESCRIPTION.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    None.\n",
        "    \n",
        "    \"\"\"\n",
        "    # init randomness\n",
        "    nn_utils_ravj._reset_random_seeds(8)\n",
        "    n_covars = 21\n",
        "    \n",
        "    #### hyper params ####\n",
        "    # number of layers\n",
        "    n_l = hp.Int(\n",
        "        name='n_l',\n",
        "        min_value=2, # not a shallow nn\n",
        "        max_value=10,\n",
        "        default=5      \n",
        "        )\n",
        "    \n",
        "    # create a funnel architecture\n",
        "    dic_units = dict()\n",
        "    for i in range(n_l - 1):\n",
        "      if i == 0:\n",
        "        dic_units['layer1'] = hp.Int(\n",
        "          name='units_l1',\n",
        "          min_value=n_covars,\n",
        "          max_value=n_covars*2,\n",
        "          step=4,\n",
        "          default=n_covars # initial value\n",
        "        )\n",
        "      else:\n",
        "        dic_units['layer' + str(i+1)] = hp.Int(\n",
        "          name='units_l' + str(i+1),\n",
        "          min_value=dic_units['layer' + str(i)],\n",
        "          max_value=dic_units['layer' + str(i)]*2,\n",
        "          step=4,\n",
        "          default=dic_units['layer' + str(i)] # initial value\n",
        "        )\n",
        "  \n",
        "    # learning rate\n",
        "    lr_r = hp.Choice(\n",
        "        name = \"lr\", \n",
        "        values = [1e-2, 1e-3, 1e-4]\n",
        "      )\n",
        "  \n",
        "    #### create model ####\n",
        "    # init\n",
        "    model = keras.Sequential()\n",
        "    # batch normalization\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "    # layers\n",
        "    for i in range(n_l - 1):\n",
        "        ikey = str(i+1)\n",
        "        \n",
        "        # compute Z score\n",
        "        model.add(\n",
        "            keras.layers.Dense(\n",
        "                units=dic_units['layer' + ikey],\n",
        "                kernel_initializer='he_normal',\n",
        "                use_bias=False, # there isn't need of a bais term because is centered\n",
        "                dtype=np.float\n",
        "            )            \n",
        "        )\n",
        "        \n",
        "        # compute A score\n",
        "        model.add(keras.layers.Activation('elu'))\n",
        "        \n",
        "        # batch normalization\n",
        "        model.add(keras.layers.BatchNormalization())\n",
        "  \n",
        "    # final layer\n",
        "    model.add(\n",
        "        keras.layers.Dense(\n",
        "          units=3, # three final classes\n",
        "          activation='softmax',\n",
        "          kernel_initializer=keras.initializers.GlorotNormal(),\n",
        "          dtype=np.float64          \n",
        "        )\n",
        "    )\n",
        "  \n",
        "    # compile model\n",
        "    model.compile(\n",
        "          optimizer=keras.optimizers.Nadam(learning_rate=lr_r),\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy']\n",
        "      )\n",
        "  \n",
        "    return(model)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYTk-FBtq_zI"
      },
      "source": [
        "# Setup data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "u7heMcISrvfY",
        "outputId": "e44a1cf2-b84b-4ede-8173-2be2961d5333"
      },
      "source": [
        "# init parasm\n",
        "SEED_VALUE = 8\n",
        "\n",
        "# read data\n",
        "df_r = pd.read_csv(\"Data/Main_DBB/model_myscale.csv\")\n",
        "\n",
        "# generate trains / validation / test database (three tables)\n",
        "vars_model = [\n",
        "    'matchweek', 'total_pts_home',\n",
        "    'npxGD_ma_home', 'npxGD_var_home', 'big_six_home',\n",
        "    'position_table_away', 'total_pts_away',\n",
        "    'npxGD_ma_away', 'npxGD_var_away', 'big_six_away',\n",
        "    'promoted_team_away', 'att_home', 'def_home', \n",
        "    'transfer_budget_home', 'ip_home', \n",
        "    'att_away', 'def_away',\n",
        "    'transfer_budget_away', 'ip_away', \n",
        "    'proba_h', 'proba_a'\n",
        "  ]\n",
        "\n",
        "# queries to part in train/val/test\n",
        "queries_model = {\n",
        "    'train':  'season < 20',\n",
        "    'validation': 'season >= 20 & matchweek < 0.45',    # matchweek 18 (standarized)\n",
        "    'test': 'season >= 20 & matchweek >= 0.45'          # normalized(18; max=38, min=2) = (18-2)/(38-2) = 0.444...\n",
        "    }\n",
        "\n",
        "dbb = tidy_bdd(df_r, queries=queries_model, objective_var='result', var=vars_model)\n",
        "\n",
        "# look data base\n",
        "dbb.get('train').get('X').describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>matchweek</th>\n",
              "      <th>total_pts_home</th>\n",
              "      <th>npxGD_ma_home</th>\n",
              "      <th>npxGD_var_home</th>\n",
              "      <th>big_six_home</th>\n",
              "      <th>position_table_away</th>\n",
              "      <th>total_pts_away</th>\n",
              "      <th>npxGD_ma_away</th>\n",
              "      <th>npxGD_var_away</th>\n",
              "      <th>big_six_away</th>\n",
              "      <th>promoted_team_away</th>\n",
              "      <th>att_home</th>\n",
              "      <th>def_home</th>\n",
              "      <th>transfer_budget_home</th>\n",
              "      <th>ip_home</th>\n",
              "      <th>att_away</th>\n",
              "      <th>def_away</th>\n",
              "      <th>transfer_budget_away</th>\n",
              "      <th>ip_away</th>\n",
              "      <th>proba_h</th>\n",
              "      <th>proba_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "      <td>2220.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.012502</td>\n",
              "      <td>-0.010084</td>\n",
              "      <td>1.257990</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.507433</td>\n",
              "      <td>0.001995</td>\n",
              "      <td>0.015510</td>\n",
              "      <td>1.255919</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.151351</td>\n",
              "      <td>0.020449</td>\n",
              "      <td>0.027483</td>\n",
              "      <td>0.114290</td>\n",
              "      <td>0.385135</td>\n",
              "      <td>0.022433</td>\n",
              "      <td>0.029752</td>\n",
              "      <td>0.115313</td>\n",
              "      <td>0.383902</td>\n",
              "      <td>0.445553</td>\n",
              "      <td>0.308803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.296652</td>\n",
              "      <td>1.001463</td>\n",
              "      <td>0.627713</td>\n",
              "      <td>0.619004</td>\n",
              "      <td>0.458361</td>\n",
              "      <td>0.299962</td>\n",
              "      <td>0.999171</td>\n",
              "      <td>0.627774</td>\n",
              "      <td>0.607556</td>\n",
              "      <td>0.458361</td>\n",
              "      <td>0.358472</td>\n",
              "      <td>0.990964</td>\n",
              "      <td>0.958845</td>\n",
              "      <td>0.969831</td>\n",
              "      <td>0.292012</td>\n",
              "      <td>0.993263</td>\n",
              "      <td>0.965821</td>\n",
              "      <td>0.970322</td>\n",
              "      <td>0.292737</td>\n",
              "      <td>0.201966</td>\n",
              "      <td>0.182642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.166821</td>\n",
              "      <td>-1.933021</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.095657</td>\n",
              "      <td>-1.758819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.231579</td>\n",
              "      <td>-2.501700</td>\n",
              "      <td>-1.334137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.423877</td>\n",
              "      <td>-2.535188</td>\n",
              "      <td>-1.334137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037577</td>\n",
              "      <td>0.023453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.811611</td>\n",
              "      <td>-0.461575</td>\n",
              "      <td>0.859697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>-0.764888</td>\n",
              "      <td>-0.433364</td>\n",
              "      <td>0.858786</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.628628</td>\n",
              "      <td>-0.719808</td>\n",
              "      <td>-0.592900</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>-0.620037</td>\n",
              "      <td>-0.727890</td>\n",
              "      <td>-0.592900</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.299620</td>\n",
              "      <td>0.173726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.178063</td>\n",
              "      <td>-0.113924</td>\n",
              "      <td>1.132317</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>-0.178016</td>\n",
              "      <td>-0.097547</td>\n",
              "      <td>1.131736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.138438</td>\n",
              "      <td>-0.158291</td>\n",
              "      <td>-0.129627</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>-0.153186</td>\n",
              "      <td>-0.157501</td>\n",
              "      <td>-0.128759</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.430700</td>\n",
              "      <td>0.279276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.663157</td>\n",
              "      <td>0.382797</td>\n",
              "      <td>1.528581</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.780702</td>\n",
              "      <td>0.670109</td>\n",
              "      <td>0.392524</td>\n",
              "      <td>1.541207</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.795474</td>\n",
              "      <td>0.705114</td>\n",
              "      <td>0.861064</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.796697</td>\n",
              "      <td>0.719727</td>\n",
              "      <td>0.861064</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.582526</td>\n",
              "      <td>0.410259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.202368</td>\n",
              "      <td>2.376635</td>\n",
              "      <td>5.257844</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.202368</td>\n",
              "      <td>2.423021</td>\n",
              "      <td>5.431222</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.647924</td>\n",
              "      <td>2.523599</td>\n",
              "      <td>2.064231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.679719</td>\n",
              "      <td>2.523599</td>\n",
              "      <td>2.064231</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.924572</td>\n",
              "      <td>0.890472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         matchweek  total_pts_home  ...      proba_h      proba_a\n",
              "count  2220.000000     2220.000000  ...  2220.000000  2220.000000\n",
              "mean      0.500000       -0.012502  ...     0.445553     0.308803\n",
              "std       0.296652        1.001463  ...     0.201966     0.182642\n",
              "min       0.000000       -2.166821  ...     0.037577     0.023453\n",
              "25%       0.250000       -0.811611  ...     0.299620     0.173726\n",
              "50%       0.500000       -0.178063  ...     0.430700     0.279276\n",
              "75%       0.750000        0.663157  ...     0.582526     0.410259\n",
              "max       1.000000        3.202368  ...     0.924572     0.890472\n",
              "\n",
              "[8 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnn5aDCfrhZm"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Pv5gBcl0Qp"
      },
      "source": [
        "## Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWNiZgsYYbNh",
        "outputId": "c89526dd-31a3-4854-a6ff-b3455c1f85cd"
      },
      "source": [
        "# save each model of the random search\n",
        "# generate figure folder\n",
        "folder_results = \"Results/Models_NN_Search\"\n",
        "if not os.path.exists(folder_results):\n",
        "  os.makedirs(folder_results)\n",
        "\n",
        "\n",
        "\n",
        "# Model 1: Funnel Architecture, Elastic Net #\n",
        "tuner_en = kt.RandomSearch(\n",
        "    hypermodel=build_model_elastic,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,\n",
        "    seed=SEED_VALUE,\n",
        "    overwrite=True,\n",
        "    directory=folder_results,\n",
        "    project_name='elastic_net'\n",
        ")\n",
        "\n",
        "# start search\n",
        "tuner_en.search(\n",
        "    dbb.get('train').get('X'),\n",
        "    dbb.get('train').get('y'),\n",
        "    epochs=20,\n",
        "    validation_data=(\n",
        "        dbb.get('validation').get('X'),\n",
        "        dbb.get('validation').get('y'),\n",
        "    )\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 05s]\n",
            "val_loss: 1.0472559928894043\n",
            "\n",
            "Best val_loss So Far: 1.0320403575897217\n",
            "Total elapsed time: 00h 01m 06s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6jcwdtQYbvj"
      },
      "source": [
        "### Look bets models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdMh0O6yjgi7",
        "outputId": "7aba7cda-5d32-4441-a6b5-d0bf71c8ca94"
      },
      "source": [
        "tuner_en.results_summary(num_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Results/Models_NN_Search/elastic_net\n",
            "Showing 1 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "elastic_lambda_l1: 0.0027877620212734613\n",
            "elastic_lambda_l2: 0.005108810096325453\n",
            "elastic_lambda_l3: 0.0015327334710733178\n",
            "elastic_lambda_l4: 0.005011946081024086\n",
            "elastic_alpha_l1: 0.731531130400211\n",
            "elastic_alpha_l2: 0.1995887063541001\n",
            "elastic_alpha_l3: 0.7915259359614659\n",
            "elastic_alpha_l4: 0.14595480067964695\n",
            "units_l1: 29\n",
            "units_l2: 21\n",
            "units_l3: 25\n",
            "lr: 0.01\n",
            "Score: 1.0320403575897217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uvmHG7rYb3_"
      },
      "source": [
        "## Lasso Penalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT6TsO46qfCv",
        "outputId": "823fc912-9ab4-451a-d796-cf6f5cd46ef7"
      },
      "source": [
        "# Model 2: Funnel Architecture, Lasso Penalization #\n",
        "tuner_lasso = kt.RandomSearch(\n",
        "    hypermodel=build_model_lasso,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    seed=SEED_VALUE,\n",
        "    overwrite=True,\n",
        "    directory=folder_results,\n",
        "    project_name='lasso'\n",
        ")\n",
        "\n",
        "# start search \n",
        "tuner_lasso.search(\n",
        "    dbb.get('train').get('X'),\n",
        "    dbb.get('train').get('y'),\n",
        "    epochs=20,\n",
        "    validation_data=(\n",
        "        dbb.get('validation').get('X'),\n",
        "        dbb.get('validation').get('y'),\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 05s]\n",
            "val_loss: 1.145202875137329\n",
            "\n",
            "Best val_loss So Far: 1.0723049640655518\n",
            "Total elapsed time: 00h 00m 29s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGXkP5HjreUv"
      },
      "source": [
        "### Look bets models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TM29BOYreU2",
        "outputId": "034f0541-d04e-475a-9b15-10479435447d"
      },
      "source": [
        "tuner_lasso.results_summary(num_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Results/Models_NN_Search/lasso\n",
            "Showing 1 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "elastic_lambda_l1: 0.002344388007872383\n",
            "elastic_lambda_l2: 0.004683772842368713\n",
            "elastic_lambda_l3: 0.005756885687430145\n",
            "elastic_lambda_l4: 0.004578557579747205\n",
            "units_l1: 29\n",
            "units_l2: 25\n",
            "units_l3: 25\n",
            "lr: 0.01\n",
            "Score: 1.0723049640655518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUNr1JuyqfAh"
      },
      "source": [
        "## Ridge Penalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztazO_j5rh-N",
        "outputId": "47fe84e1-e58f-4a9c-ccdf-e6a23989cead"
      },
      "source": [
        "# Model 3: Funnel Architecture, Ridge Penalization #\n",
        "tuner_ridge = kt.RandomSearch(\n",
        "    hypermodel=build_model_ridge,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    seed=SEED_VALUE,\n",
        "    overwrite=True,\n",
        "    directory=folder_results,\n",
        "    project_name='ridge'\n",
        ")\n",
        "\n",
        "# start search \n",
        "tuner_ridge.search(\n",
        "    dbb.get('train').get('X'),\n",
        "    dbb.get('train').get('y'),\n",
        "    epochs=20,\n",
        "    validation_data=(\n",
        "        dbb.get('validation').get('X'),\n",
        "        dbb.get('validation').get('y'),\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 06s]\n",
            "val_loss: 1.090043306350708\n",
            "\n",
            "Best val_loss So Far: 1.013405442237854\n",
            "Total elapsed time: 00h 00m 28s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNaLgEGRrspS"
      },
      "source": [
        "### Look bets models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryWFNGwRrspX",
        "outputId": "acaf55e9-775f-48b4-fe2b-f0e250e22c47"
      },
      "source": [
        "tuner_ridge.results_summary(num_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Results/Models_NN_Search/ridge\n",
            "Showing 1 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "elastic_lambda_l1: 0.0008664756601477108\n",
            "elastic_lambda_l2: 0.005746251389055045\n",
            "elastic_lambda_l3: 0.0053364602911100826\n",
            "elastic_lambda_l4: 0.005532076595873841\n",
            "units_l1: 29\n",
            "units_l2: 37\n",
            "units_l3: 33\n",
            "lr: 0.01\n",
            "Score: 1.013405442237854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFGlv1Ztqe8J"
      },
      "source": [
        "## Dropout "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytvc3EbMqe5s",
        "outputId": "7342ecc3-1636-476d-d973-fc75c8814d40"
      },
      "source": [
        "# Model 4: Funnel Architecture, Dropout #\n",
        "tuner_do = kt.RandomSearch(\n",
        "    hypermodel=build_model_dropout,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    seed=SEED_VALUE,\n",
        "    overwrite=True,\n",
        "    directory=folder_results,\n",
        "    project_name='dropout'\n",
        ")\n",
        "\n",
        "# start search \n",
        "tuner_do.search(\n",
        "    dbb.get('train').get('X'),\n",
        "    dbb.get('train').get('y'),\n",
        "    epochs=20,\n",
        "    validation_data=(\n",
        "        dbb.get('validation').get('X'),\n",
        "        dbb.get('validation').get('y'),\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 05s]\n",
            "val_loss: 1.0435572862625122\n",
            "\n",
            "Best val_loss So Far: 0.9852834343910217\n",
            "Total elapsed time: 00h 00m 29s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9Nuw4FysF_E"
      },
      "source": [
        "### Look bets models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQygw9D1sF_E",
        "outputId": "c28ca70f-123a-4abf-e831-da462a23b0ec"
      },
      "source": [
        "tuner_do.results_summary(num_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Results/Models_NN_Search/dropout\n",
            "Showing 1 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "rate_l1: 0.31687356623998275\n",
            "rate_l2: 0.00011489667217367887\n",
            "rate_l3: 0.0009435624387416539\n",
            "units_l1: 25\n",
            "units_l2: 37\n",
            "units_l3: 41\n",
            "lr: 0.01\n",
            "Score: 0.9852834343910217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zogVSiY0qe2-"
      },
      "source": [
        "## Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjxIWEHjqex1",
        "outputId": "e218d0f5-7c1c-4756-bbbb-00f368a9586d"
      },
      "source": [
        "# Model 5: Random Funnel Architecture, BatchNormalization #\n",
        "tuner_bn = kt.RandomSearch(\n",
        "    hypermodel=build_model_bn,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    seed=SEED_VALUE,\n",
        "    overwrite=True,\n",
        "    directory=folder_results,\n",
        "    project_name='batch_normalization'\n",
        ")\n",
        "\n",
        "# start search \n",
        "tuner_bn.search(\n",
        "    dbb.get('train').get('X'),\n",
        "    dbb.get('train').get('y'),\n",
        "    epochs=20,\n",
        "    validation_data=(\n",
        "        dbb.get('validation').get('X'),\n",
        "        dbb.get('validation').get('y'),\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 00m 07s]\n",
            "val_loss: 1.0170873403549194\n",
            "\n",
            "Best val_loss So Far: 1.0170873403549194\n",
            "Total elapsed time: 00h 00m 45s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOmU8aFrsV2c"
      },
      "source": [
        "### Look bets models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYjBGNYBsV2d",
        "outputId": "9ec08114-21a6-4883-9431-c901e8137109"
      },
      "source": [
        "tuner_bn.results_summary(num_trials=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in Results/Models_NN_Search/batch_normalization\n",
            "Showing 1 best trials\n",
            "Objective(name='val_loss', direction='min')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "n_l: 5\n",
            "units_l1: 37\n",
            "units_l2: 33\n",
            "units_l3: 25\n",
            "units_l4: 29\n",
            "lr: 0.001\n",
            "units_l5: 61\n",
            "units_l6: 37\n",
            "units_l7: 53\n",
            "units_l8: 49\n",
            "Score: 1.0170873403549194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SwcdK5kWFFz"
      },
      "source": [
        "# Build HyperModels with optimal instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmRyE3epWqEK"
      },
      "source": [
        "def get_hypermodel(tn):\n",
        "  # get best model\n",
        "  best_hypermodel_instance = tn.get_best_hyperparameters(1)[0]\n",
        "\n",
        "  # instanciate \n",
        "  best_model = tn.hypermodel.build(best_hypermodel_instance)\n",
        "\n",
        "  return best_model\n",
        "\n",
        "# init each model\n",
        "fitnn_en = get_hypermodel(tuner_en)\n",
        "fitnn_lasso = get_hypermodel(tuner_lasso)\n",
        "fitnn_ridge = get_hypermodel(tuner_ridge)\n",
        "fitnn_do = get_hypermodel(tuner_do)\n",
        "fitnn_bn = get_hypermodel(tuner_bn)\n",
        "\n",
        "# save each model in an array\n",
        "list_models = [\n",
        "  fitnn_en, fitnn_lasso, fitnn_ridge, fitnn_do, fitnn_bn\n",
        "]\n",
        "\n",
        "name_models = ['elastic_net', 'lasso', 'ridge', 'dropout', 'batch_norm']\n",
        "\n",
        "dict_models = dict(zip(name_models, list_models))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcRWg98Wp-g"
      },
      "source": [
        "def fit_model(dbb, model, seed=42):\n",
        "    # init randomness\n",
        "    nn_utils_ravj._reset_random_seeds(seed=seed)\n",
        "\n",
        "    # get train database\n",
        "    X_train=dbb.get('train')['X']\n",
        "    Y_train=dbb.get('train')['y']\n",
        "\n",
        "    # compile model\n",
        "    model.compile(\n",
        "            optimizer=keras.optimizers.Nadam(learning_rate=1e-2),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "    # early stopping\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        min_delta=0.01,\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # train model\n",
        "    model.fit(\n",
        "        x=X_train,\n",
        "        y=Y_train,\n",
        "        epochs=1000,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        verbose=0,\n",
        "        callbacks=[early_stop],\n",
        "        validation_data=(dbb.get('validation')['X'], dbb.get('validation')['y']),\n",
        "        validation_batch_size=len(dbb.get('validation')['X'])    #complete gradient\n",
        "    )\n",
        "\n",
        "    return()\n",
        "\n",
        "\n",
        "def eval_model(dbb, model, nsplit_cv=5, ntest_cv=1, verbose=True, seed=42):\n",
        "    # merge train and validation in one dataframe\n",
        "    X_list = [v2 for k1, dics in dbb.items() if k1 != 'test' for k2, v2 in dics.items() if k2 == \"X\"]\n",
        "    Y_list = [v2 for k1, dics in dbb.items() if k1 != 'test' for k2, v2 in dics.items() if k2 == \"y\"]\n",
        "\n",
        "    X_data = pd.concat(X_list)\n",
        "    Y_data = pd.concat(Y_list)\n",
        "\n",
        "    # save\n",
        "    array_errors = np.zeros((nsplit_cv, 2))\n",
        "\n",
        "    # split data in nsplit_cv-folds\n",
        "    if verbose:\n",
        "        print(\"fold: \", end='')\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=nsplit_cv, test_size=ntest_cv, gap=0)\n",
        "    i = 0\n",
        "    \n",
        "    for index_train, index_val in tscv.split(X_data):\n",
        "        # get a look in the number of iterations\n",
        "        if verbose:\n",
        "            print(str(i+1) + \", \", end=\"\")\n",
        "            \n",
        "        # save train/val database\n",
        "        dbb_val = {\n",
        "            'train': {\n",
        "                'X': X_data.iloc[index_train],\n",
        "                'y': Y_data.iloc[index_train]\n",
        "            },\n",
        "            'validation': {\n",
        "                'X': X_data.iloc[index_val],\n",
        "                'y': Y_data.iloc[index_val]\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # shell model\n",
        "        model_copy = keras.models.clone_model(model)\n",
        "        \n",
        "        # fit model\n",
        "        fit_model(dbb_val, model_copy, seed)\n",
        "        \n",
        "        # evaluate time series cross validation data\n",
        "        # append metrics\n",
        "        array_errors[i] = model_copy.evaluate(\n",
        "            dbb_val.get('validation').get('X'),\n",
        "            dbb_val.get('validation').get('y'),\n",
        "            verbose=0            \n",
        "        )\n",
        "\n",
        "        # update index\n",
        "        i += 1\n",
        "\n",
        "\n",
        "    # get statistics of the metrics\n",
        "    # loss\n",
        "    mean_loss = np.mean(array_errors[:, 0], axis=0)\n",
        "    std_loss = np.std(array_errors[:, 0], axis=0)\n",
        "\n",
        "    # acc\n",
        "    mean_acc = np.mean(array_errors[:, 1], axis=0)\n",
        "    std_acc = np.std(array_errors[:, 1], axis=0)\n",
        "\n",
        "    # return\n",
        "    loss_stats = np.array((mean_loss, std_loss))\n",
        "    acc_stats = np.array((mean_acc, std_acc))\n",
        "\n",
        "    return(loss_stats, acc_stats)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv42rSoBVgKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a6d4f7-7ccf-4736-805f-96fcc7e5627f"
      },
      "source": [
        "# train each model\n",
        "dict_models_eval = dict()\n",
        "\n",
        "# get number of cross validation sets\n",
        "n_games_per_matchweek = 10 # there are 10 game per matchweek\n",
        "n_cv = dbb.get('validation').get('y').shape[0] // n_games_per_matchweek\n",
        "\n",
        "# evaluate models in a TCV\n",
        "for name_model, model in dict_models.items():\n",
        "  print(\"training model: \" + name_model)\n",
        "  dict_models_eval[name_model] = eval_model(\n",
        "      dbb, \n",
        "      model, \n",
        "      nsplit_cv=n_cv, \n",
        "      ntest_cv=n_games_per_matchweek,\n",
        "      verbose=True,\n",
        "      seed=SEED_VALUE\n",
        "  )\n",
        "  print(\"\\n\\n\")\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model: elastic_net\n",
            "fold: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \n",
            "\n",
            "\n",
            "training model: lasso\n",
            "fold: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \n",
            "\n",
            "\n",
            "training model: ridge\n",
            "fold: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \n",
            "\n",
            "\n",
            "training model: dropout\n",
            "fold: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \n",
            "\n",
            "\n",
            "training model: batch_norm\n",
            "fold: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQG15BvHVgRw"
      },
      "source": [
        "## Plot accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRnx6z7OWZw5"
      },
      "source": [
        "# get accuracies\n",
        "names_models = list(dict_models_eval.keys())\n",
        "names_cols = ['mean', 'std']\n",
        "loss_array = np.vstack([value[0] for value in dict_models_eval.values()])\n",
        "acc_array = np.vstack([value[1] for value in dict_models_eval.values()])\n",
        "\n",
        "# to dataframe\n",
        "df_loss = pd.DataFrame(loss_array, index=names_models, columns=names_cols).sort_values(['mean', 'std'], ascending=[True, True])\n",
        "df_acc = pd.DataFrame(acc_array, index=names_models, columns=names_cols).sort_values(['mean', 'std'], ascending=[False, True])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "kvfsGRskWaBz",
        "outputId": "f55810ac-cc86-4611-eab8-18584c03ec76"
      },
      "source": [
        "# get names\n",
        "names_figures = list(df_acc.index)\n",
        "x_aux = np.arange(len(names_figures))\n",
        "\n",
        "# plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.errorbar(\n",
        "    x_aux,\n",
        "    df_acc['mean'],\n",
        "    yerr = df_acc['std'],\n",
        "    capsize=5,\n",
        "    elinewidth=1,\n",
        "    color ='black',\n",
        "    ecolor='gray',\n",
        "    fmt='o'\n",
        ")\n",
        "\n",
        "# add decorators\n",
        "plt.title(\"Precisón por Modelo\", fontsize=30)\n",
        "\n",
        "ax.set_ylabel('Precisión', fontsize=20)\n",
        "\n",
        "ax.tick_params(axis='y', labelsize=15)\n",
        "ax.tick_params(axis='x', labelsize=15)\n",
        "\n",
        "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
        "\n",
        "plt.ylim(bottom=0, top=1)\n",
        "\n",
        "plt.xticks(x_aux, names_figures, fontsize=20)\n",
        "plt.margins(0.2)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "\n",
        "# reescale plot\n",
        "fig.tight_layout(rect=[0, 0.03, 1*2, 0.95*2])\n",
        "\n",
        "# show figure \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I13D_uCSWaO1",
        "outputId": "85494d43-c9b5-4932-b9aa-90fa3d1fb122"
      },
      "source": [
        "# get names\n",
        "names_figures = list(df_loss.index)\n",
        "x_aux = np.arange(len(names_figures))\n",
        "\n",
        "# plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.errorbar(\n",
        "    x_aux,\n",
        "    df_loss['mean'],\n",
        "    yerr = df_loss['std'],\n",
        "    capsize=5,\n",
        "    elinewidth=1,\n",
        "    color ='black',\n",
        "    ecolor='gray',\n",
        "    fmt='o'\n",
        ")\n",
        "\n",
        "# add decorators\n",
        "plt.title(\"Pérdida por Modelo\", fontsize=30)\n",
        "\n",
        "ax.set_ylabel('Pérdida', fontsize=20)\n",
        "\n",
        "ax.tick_params(axis='y', labelsize=15)\n",
        "ax.tick_params(axis='x', labelsize=15)\n",
        "\n",
        "\n",
        "plt.xticks(x_aux, names_figures, fontsize=20)\n",
        "plt.margins(0.2)\n",
        "plt.subplots_adjust(bottom=0.15)\n",
        "\n",
        "# reescale plot\n",
        "fig.tight_layout(rect=[0, 0.03, 1*2, 0.95*2])\n",
        "\n",
        "# show figure \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}